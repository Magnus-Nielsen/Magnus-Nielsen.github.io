[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Magnus Lindgaard Nielsen",
    "section": "",
    "text": "I am a Ph.D. fellow at the Copenhagen Center for Social Data Science at the University of Copenhagen. My goal is to make the world a more data-driven place, both using predictive machine learning and by doing causal inference using quasi-experimental methods.\nMy current research focuses on how to efficiently utilize data about the Danish youth to predict later life events.\nI’m part of the Nation-scale social networks project, which is a joint collaboration between the University of Copenhagen, Technical University of Denmark and Statistics Denmark."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Magnus Lindgaard Nielsen",
    "section": "",
    "text": "This is my personal website, where I display small snippets of code and bibliographical information about me.\n\n Say hi if you see me!"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Magnus Lindgaard Nielsen",
    "section": "",
    "text": "Introduction to Social Data Science, Summer 2022\nCoding Café, an offer to master’s students in the MSc in Social Data Science , mainly assisting with exercies in the two courses Advanced Social Data Science I and Advanced Social Data Science II in addition to helping students scrape data for use in their master’s thesis, Spring 2022\nSocial Data Analysis, Spring 2021\nPrinciple of Economics A, Fall 2018"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Magnus Lindgaard Nielsen",
    "section": "",
    "text": "As part of a seminar in applications of machine learning, I devised a method to dettect structural breaks in prediction or classification problems with repeated cross sections.\n\n\nA novel method to detect structural breaks in classification or prediction problems with repeated cross sections is proposed. The theoretical foundation is presented and the power and robustness of the method in a specific use case is showcased with a simulation study. The method utilizes that the generalization error of a model is an IID sample from a distribution which can only change between periods if the data generating process changes. Utilizing holdout data in each period, any changes in performance can then be attributed to a structural break in the data. This is tested utilizing tests for equality of means between the samples.\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport statsmodels.api as sm\n\nnp.random.seed(299)\nsns.color_palette('colorblind')\n\nnsample1 = 2000\nnsample2 = 500\nnsample3 = 500\n\n\n# period 1\nx1 = np.random.normal(size=nsample1)\nbeta1 = 4\ne1 = np.random.normal(size=nsample1, scale=2)\ny1 = np.dot(x1, beta1) + e1\n\n# development and holdout data\n\nx1tr = x1[:1500]\nx1te = x1[1500:]\n\ny1tr = y1[:1500]\ny1te = y1[1500:]\n\n# period 2\nx2 = np.random.normal(size=nsample2)\nbeta2 = 8\ne2 = np.random.normal(size=nsample2, scale=2)\ny2 = np.dot(x2, beta2) + e2\n\n# period 3\nx3 = np.random.normal(size=nsample3)\nbeta3 = 4\ne3 = np.random.normal(size=nsample3, scale=1)\ny3 = np.dot(x3, beta3) + e3\n\n# collection of targets\n\ny_list = [y1te, y2, y3]\n\n# fit model\nmodel = sm.OLS(y1tr, x1tr)\nresults = model.fit()\n\n# predict values\npred1 = results.predict(x1te)\npred2 = results.predict(x2)\npred3 = results.predict(x3)\n\n# list of predictions\npred_list = [pred1, pred2, pred3]\n\n# calculate mean squared errors\nerrs = {}\n    \nfor i in range(3):\n    errs[i+1] = [(i-j)**2 for (i,j) in zip(pred_list[i], y_list[i])]\n\n# convert to dataframe\ndf_from_dict = pd.DataFrame.from_dict(errs, orient='index').T\ndf_melt = pd.melt(df_from_dict.reset_index(), id_vars=['index'])\ndf = df_melt[['variable', 'value']]\ndf = df.rename(columns={'variable': 'Period', 'value': 'Mean squared error'})\n\n# create figure\n\nplt.figure(figsize=(9, 6))\nfig = sns.histplot(x=\"Mean squared error\",\n             data=df,\n             bins=25,\n             hue=\"Period\",\n             kde=True,\n             log_scale=True,\n             element=\"step\",\n             palette='colorblind')\n\n# change label and tick size\nfig.set_xlabel(\"Mean squared error\",fontsize=15)\nfig.set_ylabel(\"Count\",fontsize=15)\nfig.tick_params(labelsize=10)\n\nplt.show()\n\n\n\n\n\nFigure 1: Mean squared error distribution across time periods"
  }
]